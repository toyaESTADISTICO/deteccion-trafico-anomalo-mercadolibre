<!DOCTYPE html>
<html>
<head>
    <title>Dashboard de Detección de Tráfico Anómalo</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 20px;
            max-width: 1200px;
            margin: 0 auto;
        }
        .container {
            display: flex;
            flex-wrap: wrap;
        }
        .metric {
            background: #f8f9fa;
            padding: 15px;
            margin: 10px;
            border-radius: 5px;
            flex: 1;
            text-align: center;
        }
        .metric h3 {
            margin: 0;
            color: #333;
        }
        .metric p {
            font-size: 24px;
            font-weight: bold;
            margin: 10px 0;
            color: #0066cc;
        }
        .chart {
            width: 100%;
            margin: 20px 0;
            padding: 15px;
            background: #f8f9fa;
            border-radius: 5px;
        }
        h1, h2 {
            color: #333;
        }
        .tab {
            overflow: hidden;
            border: 1px solid #ccc;
            background-color: #f1f1f1;
        }
        .tab button {
            background-color: inherit;
            float: left;
            border: none;
            outline: none;
            cursor: pointer;
            padding: 14px 16px;
        }
        .tab button:hover {
            background-color: #ddd;
        }
        .tab button.active {
            background-color: #ccc;
        }
        .tabcontent {
            display: none;
            padding: 6px 12px;
            border: 1px solid #ccc;
            border-top: none;
        }
        .footer {
            margin-top: 30px;
            padding-top: 10px;
            border-top: 1px solid #eee;
            font-size: 12px;
            color: #777;
        }
        /* Estilos para la tipología de bots */
        .percentage {
            font-weight: bold;
            color: #e74c3c;
        }
        .characteristic {
            margin-bottom: 10px;
        }
        .metrics {
            background-color: #f8f9fa;
            border-left: 4px solid #007bff;
            padding: 10px 15px;
            margin-bottom: 20px;
        }
        .metrics strong {
            color: #0056b3;
        }
        .objective {
            background-color: #e8f4f8;
            padding: 10px 15px;
            border-radius: 5px;
            margin-top: 15px;
        }
        .objective-title {
            font-weight: bold;
            margin-bottom: 5px;
        }
    </style>
    <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
</head>
<body>
    <h1>Detección de Tráfico Web Anómalo en Mercado Libre</h1>
    <p>Dashboard interactivo para visualizar y analizar patrones de tráfico automatizado</p>

    <div class="container">
        <div class="metric">
            <h3>Total de solicitudes</h3>
            <p>120,000</p>
        </div>
        <div class="metric">
            <h3>IPs únicas</h3>
            <p>84,253</p>
        </div>
        <div class="metric">
            <h3>Sesiones únicas</h3>
            <p>119,408</p>
        </div>
        <div class="metric">
            <h3>% de tráfico bot</h3>
            <p>24.5%</p>
        </div>
    </div>

    <h2>Patrones de tráfico</h2>

<div class="tab">
    <button class="tablinks" onclick="openTab(event, 'Tab1')" id="defaultOpen">Distribución temporal</button>
    <button class="tablinks" onclick="openTab(event, 'Tab2')">Perfiles de bots</button>
    <button class="tablinks" onclick="openTab(event, 'Tab3')">Geolocalización</button>
    <button class="tablinks" onclick="openTab(event, 'Tab4')">Métricas del modelo</button>
    <button class="tablinks" onclick="openTab(event, 'Tab5')">Comportamiento por IP/Sesión</button>
    <button class="tablinks" onclick="openTab(event, 'Tab6')">Patrones temporales</button>
    <button class="tablinks" onclick="openTab(event, 'Tab7')">Tráfico sospechoso</button>
</div>

    <div id="Tab1" class="tabcontent">
        <div class="chart">
            <h3>Distribución de solicitudes por hora del día</h3>
            <div id="hourChart"></div>
        </div>

        <div class="container">
            <div class="chart" style="width: 48%;">
                <h3>Distribución por día de la semana</h3>
                <div id="dayChart"></div>
            </div>
            <div class="chart" style="width: 48%;">
                <h3>Códigos de respuesta</h3>
                <div id="responseChart"></div>
            </div>
        </div>
    </div>

    <div id="Tab2" class="tabcontent">
        <h3>Perfiles de tráfico automatizado detectados</h3>

        <div class="chart">
            <h3>Tipos de bots identificados</h3>
            <div id="botTypeChart"></div>
            
            <h2>Tipología de Bots Detectados</h2>

            <h3>1. Scrapers de alta velocidad <span class="percentage">(7.28%)</span></h3>
            <div class="characteristic">
                <p>Utilizan navegadores reales o emulan sus características para extraer datos rápidamente.</p>
            </div>
            <div class="metrics">
                <ul>
                    <li><strong>has_browser:</strong> 1273% mayor que la media</li>
                    <li><strong>is_business_hour:</strong> 190% mayor que la media</li>
                    <li><strong>has_platform:</strong> 169% mayor que la media</li>
                    <li>Presentan consistencia en el tamaño de respuestas (baja variabilidad)</li>
                </ul>
            </div>
            <div class="objective">
                <div class="objective-title">Objetivo probable:</div>
                <p>Extracción rápida de datos específicos (precios, productos)</p>
            </div>

            <h3>2. Bots API <span class="percentage">(61.86%) - El grupo dominante</span></h3>
            <div class="characteristic">
                <p>Extremadamente simplificados y directos en sus solicitudes. No utilizan navegadores convencionales ni incluyen parámetros complejos.</p>
            </div>
            <div class="metrics">
                <ul>
                    <li><strong>url_entropy:</strong> 100% menor que la media</li>
                    <li><strong>interval_uniformity:</strong> 100% menor que la media</li>
                    <li><strong>page_req_ratio:</strong> 100% menor que la media</li>
                    <li>Alta predictibilidad en patrones de acceso</li>
                </ul>
            </div>
            <div class="objective">
                <div class="objective-title">Objetivo probable:</div>
                <p>Consultas automatizadas para extracción masiva de datos estructurados</p>
            </div>

            <h3>3. Crawlers lentos/distribuidos <span class="percentage">(29.78%)</span></h3>
            <div class="characteristic">
                <p>Comportamiento más similar a navegación humana pero sistemático, con diversificación en tipos de páginas visitadas.</p>
            </div>
            <div class="metrics">
                <ul>
                    <li><strong>param_count:</strong> 233% mayor que la media</li>
                    <li><strong>has_query_params:</strong> 233% mayor que la media</li>
                    <li><strong>search_req_ratio:</strong> 233% mayor que la media</li>
                    <li>Diversificación en tipos de páginas visitadas (checkout, búsqueda, páginas regulares)</li>
                </ul>
            </div>
            <div class="objective">
                <div class="objective-title">Objetivo probable:</div>
                <p>Indexación completa o monitoreo de cambios en productos/precios</p>
            </div>

            <h3>4. Bots de navegación repetitiva <span class="percentage">(1.08%)</span></h3>
            <div class="characteristic">
                <p>Comportamiento más sofisticado que simula navegación humana errática, con mayor complejidad en patrones de solicitudes.</p>
            </div>
            <div class="metrics">
                <ul>
                    <li><strong>url_entropy:</strong> 9188% mayor que la media</li>
                    <li><strong>interval_uniformity:</strong> 9188% mayor que la media</li>
                    <li><strong>range_bytes:</strong> 9183% mayor que la media</li>
                    <li>Mayor complejidad en patrones de solicitudes y visitas a múltiples recursos</li>
                </ul>
            </div>
            <div class="objective">
                <div class="objective-title">Objetivo probable:</div>
                <p>Evasión de sistemas de detección avanzados mediante simulación de comportamiento humano impredecible</p>
            </div>
        </div>
    </div>

    <div id="Tab3" class="tabcontent">
        <div class="chart">
            <h3>Distribución geográfica del tráfico</h3>
            <div id="countryChart"></div>
        </div>

        <div class="chart">
            <h3>Países con mayor proporción de tráfico automatizado</h3>
            <div id="botCountryChart"></div>
        </div>
    </div>

    <div id="Tab4" class="tabcontent">
        <div class="container">
            <div class="chart" style="width: 48%;">
                <h3>Métricas globales</h3>
                <ul>
                    <li><strong>Accuracy</strong>: 96.78%</li>
                    <li><strong>Precision</strong>: 95.27%</li>
                    <li><strong>Recall</strong>: 92.07%</li>
                    <li><strong>F1 Score</strong>: 93.64%</li>
                    <li><strong>ROC AUC</strong>: 0.9940</li>
                    <li><strong>PR AUC</strong>: 0.9837</li>
                </ul>
            </div>
            <div class="chart" style="width: 48%;">
                <h3>Matriz de Confusión</h3>
                <div id="confusionMatrix"></div>
            </div>
        </div>

        <div class="chart">
            <h3>Rendimiento por tipo de bot</h3>
            <table width="100%" border="1" cellpadding="5" cellspacing="0">
                <tr>
                    <th>Tipo</th>
                    <th>Precision</th>
                    <th>Recall</th>
                    <th>F1</th>
                </tr>
                <tr>
                    <td>Scrapers alta velocidad</td>
                    <td>0.9897</td>
                    <td>0.9995</td>
                    <td>0.9962</td>
                </tr>
                <tr>
                    <td>Bots API</td>
                    <td>0.9687</td>
                    <td>0.9993</td>
                    <td>0.9841</td>
                </tr>
                <tr>
                    <td>Crawlers lentos</td>
                    <td>0.9339</td>
                    <td>0.9923</td>
                    <td>0.9634</td>
                </tr>
                <tr>
                    <td>Bots navegación repetitiva</td>
                    <td>1.0000</td>
                    <td>1.0000</td>
                    <td>0.9984</td>
                </tr>
            </table>
        </div>
    </div>


    <div id="Tab5" class="tabcontent">
    <h3>Análisis de comportamiento por IP y sesión</h3>

    <div class="chart">
        <h4>Top 10 IPs con más solicitudes</h4>
        <table width="100%" border="1" cellpadding="5" cellspacing="0">
            <tr>
                <th>IP</th>
                <th>Solicitudes</th>
            </tr>
            <tr><td>192.168.0.102</td><td>172</td></tr>
            <tr><td>192.168.0.187</td><td>170</td></tr>
            <tr><td>192.168.0.229</td><td>168</td></tr>
            <tr><td>192.168.0.83</td><td>166</td></tr>
            <tr><td>192.168.0.12</td><td>166</td></tr>
            <tr><td>192.168.0.132</td><td>164</td></tr>
            <tr><td>192.168.0.28</td><td>164</td></tr>
            <tr><td>192.168.0.219</td><td>163</td></tr>
            <tr><td>192.168.0.43</td><td>163</td></tr>
            <tr><td>192.168.0.44</td><td>162</td></tr>
        </table>
    </div>

    <div class="chart">
        <h4>Top 10 User Agents</h4>
        <table width="100%" border="1" cellpadding="5" cellspacing="0">
            <tr>
                <th>User Agent</th>
                <th>Solicitudes</th>
            </tr>
            <tr><td>Mozilla/5.0 (Linux; Android 11; Pixel 5)</td><td>20060</td></tr>
            <tr><td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)</td><td>20024</td></tr>
            <tr><td>Mozilla/5.0 (iPhone; CPU iPhone OS 14_6 like Mac OS X)</td><td>19955</td></tr>
            <tr><td>Mozilla/5.0 (Windows NT 10.0; Win64; x64)</td><td>19943</td></tr>
            <tr><td>python-requests/2.25.1</td><td>9046</td></tr>
            <tr><td>Go-http-client/1.1</td><td>9024</td></tr>
            <tr><td>Scrapy/2.5.0 (+https://scrapy.org)</td><td>8980</td></tr>
            <tr><td>curl/7.68.0</td><td>8950</td></tr>
            <tr><td>Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7; rv:85.0) Gecko/20100101 Firefox/85.0</td><td>2030</td></tr>
            <tr><td>Mozilla/5.0 (Windows NT 10.0; Win64; x64) HeadlessChrome/90.0</td><td>1988</td></tr>
        </table>
    </div>

    <div class="chart">
        <h4>Top 10 URLs visitadas</h4>
        <table width="100%" border="1" cellpadding="5" cellspacing="0">
            <tr>
                <th>URL</th>
                <th>Solicitudes</th>
            </tr>
            <tr><td>/orders</td><td>7442</td></tr>
            <tr><td>/profile</td><td>7318</td></tr>
            <tr><td>/checkout</td><td>7304</td></tr>
            <tr><td>/item/67890</td><td>7293</td></tr>
            <tr><td>/item/12345</td><td>7272</td></tr>
            <tr><td>/search?q=celular</td><td>7263</td></tr>
            <tr><td>/home</td><td>7239</td></tr>
            <tr><td>/cart</td><td>7169</td></tr>
            <tr><td>/search?q=notebook</td><td>7168</td></tr>
            <tr><td>/category/electronics</td><td>7143</td></tr>
        </table>
    </div>

    <div class="chart">
        <h4>Observaciones clave sobre comportamiento por IP y sesión</h4>
        <ul>
            <li>La distribución de solicitudes por IP muestra una clara estrategia de distribución de tráfico automatizado. Las IPs top tienen cantidades muy similares de solicitudes (162-172), sugiriendo una configuración deliberada para mantenerse por debajo de umbrales típicos de detección.</li>
            <li>Aproximadamente un tercio del tráfico utiliza user-agents claramente automatizados (python-requests, Go-http-client, Scrapy, curl), una señal inequívoca de tráfico no humano.</li>
            <li>La distribución sorprendentemente uniforme entre las URLs más visitadas (todas entre 7,100-7,400 solicitudes) indica un escaneo sistemático de todos los principales endpoints de la plataforma.</li>
        </ul>
    </div>
</div>

<!-- Nueva pestaña: Análisis de patrones temporales -->
<div id="Tab6" class="tabcontent">
    <h3>Análisis de patrones temporales por sesión/IP</h3>

    <div class="chart">
        <h4>Distribución de intervalos entre solicitudes</h4>
        <div id="intervalChart" style="width:100%;height:400px;"></div>
        <p><strong>Interpretación:</strong> La gráfica muestra la desviación estándar de intervalos entre solicitudes por sesión. Se observa que:</p>
        <ul>
            <li>Solo 433 de 119,408 sesiones (0.36%) realizan más de una solicitud</li>
            <li>De estas, solo 123 sesiones tienen suficientes solicitudes para calcular una desviación estándar confiable</li>
            <li>El umbral de sospecha está en intervalos menores a 0.5 segundos, físicamente imposibles para interacción humana</li>
            <li>Se observa un pico significativo en desviaciones estándar muy bajas (cerca de 0), indicando intervalos mecánicamente regulares típicos de automatización</li>
        </ul>
    </div>

    <div class="chart">
        <h4>Estadísticas de intervalos temporales</h4>
        <ul>
            <li><strong>Sesiones con más de una solicitud:</strong> 433 de 119408 (0.36%)</li>
            <li><strong>Sesiones con desviación estándar calculable:</strong> 123</li>
            <li><strong>Rango de desviación estándar:</strong> 1.45 - 7661.36 segundos</li>
            <li><strong>Media de intervalos:</strong> 2861.1 segundos (~48 minutos)</li>
            <li><strong>Mediana de intervalos:</strong> 1866.17 segundos (~31 minutos)</li>
        </ul>
        <p><strong>Hallazgo clave:</strong> La estrategia predominante en el tráfico automatizado es realizar una única solicitud por sesión (99.64% de los casos), eludiendo así los sistemas de detección basados en comportamiento intra-sesión.</p>
    </div>
</div>

<!-- Nueva pestaña: Tráfico sospechoso detectado -->
<div id="Tab7" class="tabcontent">
    <h3>Identificación de ejemplos concretos de tráfico sospechoso</h3>

    <div class="chart">
        <h4>IPs con mayor actividad sospechosa</h4>
        <table width="100%" border="1" cellpadding="5" cellspacing="0">
            <tr>
                <th>IP (país)</th>
                <th>Sesiones de bot</th>
                <th>% del total</th>
            </tr>
            <tr><td>192.168.0.102 (??)</td><td>172</td><td>100.0%</td></tr>
            <tr><td>192.168.0.187 (??)</td><td>170</td><td>100.0%</td></tr>
            <tr><td>192.168.0.229 (??)</td><td>168</td><td>100.0%</td></tr>
            <tr><td>192.168.0.83 (??)</td><td>166</td><td>100.0%</td></tr>
            <tr><td>192.168.0.12 (??)</td><td>165</td><td>99.4%</td></tr>
            <tr><td>192.168.0.132 (??)</td><td>164</td><td>100.0%</td></tr>
            <tr><td>192.168.0.28 (??)</td><td>163</td><td>99.4%</td></tr>
            <tr><td>192.168.0.219 (??)</td><td>162</td><td>99.4%</td></tr>
            <tr><td>192.168.0.43 (??)</td><td>162</td><td>99.4%</td></tr>
            <tr><td>192.168.0.92 (??)</td><td>162</td><td>100.0%</td></tr>
        </table>
    </div>

    <div class="chart">
        <h4>Caso de estudio: IP 192.168.0.102</h4>
        <div style="display: flex; flex-wrap: wrap;">
            <div style="flex: 1; min-width: 300px;">
                <h5>Perfil general:</h5>
                <ul>
                    <li><strong>Total de sesiones:</strong> 172</li>
                    <li><strong>Sesiones clasificadas como bot:</strong> 172 (100%)</li>
                    <li><strong>País de origen:</strong> Desconocido (??)</li>
                </ul>

                <h5>Distribución por tipo de bot:</h5>
                <ul>
                    <li>Scrapers de alta velocidad: 0 (0.0%)</li>
                    <li>Bots API: 170 (98.8%)</li>
                    <li>Crawlers lentos/distribuidos: 0 (0.0%)</li>
                    <li>Bots de navegación repetitiva: 2 (1.2%)</li>
                </ul>
            </div>

            <div style="flex: 1; min-width: 300px;">
                <h5>User-Agents utilizados:</h5>
                <ol>
                    <li>curl/7.68.0</li>
                    <li>Scrapy/2.5.0 (+https://scrapy.org)</li>
                    <li>python-requests/2.25.1</li>
                    <li>Go-http-client/1.1</li>
                </ol>
            </div>
        </div>

        <div>
            <h5>Interpretación:</h5>
            <p>Esta IP representa un caso claro de actividad automatizada para extracción de datos. Los indicadores principales son:</p>
            <ul>
                <li>Uso exclusivo de herramientas de automatización como user-agents (curl, Scrapy, python-requests, Go-http-client)</li>
                <li>Distribución abrumadora de solicitudes clasificadas como "Bots API" (98.8%), indicando acceso directo y sistemático a endpoints</li>
                <li>Origen geográfico desconocido (país "??"), sugiriendo posible uso de proxy o VPN para ocultar ubicación real</li>
                <li>Patrón de una solicitud por sesión, técnica típica para evadir sistemas de detección basados en comportamiento de sesión</li>
            </ul>
            <p>Este perfil corresponde a una operación de scraping avanzada que emplea múltiples herramientas de automatización y técnicas de evasión para extraer datos sistemáticamente de la plataforma.</p>
        </div>
    </div>

    <div class="chart">
        <h4>Distribución de tipos de bot por país</h4>
        <div id="botDistributionByCountry"></div>
        <p><strong>Observación clave:</strong> Las IPs con país desconocido ("??") muestran un predominio de Bots API (casi 100%), mientras que en países legítimos existe una distribución más variada con predominio de Crawlers lentos/distribuidos. Esto sugiere que el tráfico más agresivo y directo intenta ocultar su origen geográfico.</p>
    </div>
</div>

    <div class="footer">
        <p><strong>Desarrollado por:</strong> Andrés Felipe Montoya Morales | <strong>Contacto:</strong> 3116225298</p>
        <p><em>Dashboard interactivo desarrollado como complemento para la prueba técnica de Científico de Datos en Ciberseguridad para Mercado Libre, Mayo 2025.</em></p>
    </div>

    <script>
        // Tab functionality
        function openTab(evt, tabName) {
            var i, tabcontent, tablinks;
            tabcontent = document.getElementsByClassName("tabcontent");
            for (i = 0; i < tabcontent.length; i++) {
                tabcontent[i].style.display = "none";
            }
            tablinks = document.getElementsByClassName("tablinks");
            for (i = 0; i < tablinks.length; i++) {
                tablinks[i].className = tablinks[i].className.replace(" active", "");
            }
            document.getElementById(tabName).style.display = "block";
            evt.currentTarget.className += " active";
        }

document.addEventListener('DOMContentLoaded', function() {
    // Hour distribution chart
    var hourData = [{
        x: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],
        y: [11000, 11200, 11100, 10800, 10500, 3800, 3700, 3600, 3700, 3800, 3700, 3800, 3900, 3800, 3700, 3400, 3200, 3100, 2900, 2800, 3000, 3100, 3000, 2900],
        type: 'bar',
        marker: {color: '#ff6b6b'}
    }];
    Plotly.newPlot('hourChart', hourData, {title: 'Distribución por hora del día'});

    // Day distribution chart
    var dayData = [{
        x: ['Lunes', 'Martes', 'Miércoles', 'Jueves', 'Viernes', 'Sábado', 'Domingo'],
        y: [65000, 18000, 17000, 17000, 3000, 0, 0],
        type: 'bar',
        marker: {color: '#4ecdc4'}
    }];
    Plotly.newPlot('dayChart', dayData, {title: 'Distribución por día de la semana'});

    // Response code chart
    var responseData = [{
        x: ['200', '404', '500', '302'],
        y: [110000, 5000, 4000, 1000],
        type: 'bar',
        marker: {color: '#1a535c'}
    }];
    Plotly.newPlot('responseChart', responseData, {title: 'Distribución de códigos de respuesta'});

    // Bot type chart
    var botTypeData = [{
        values: [7.28, 61.86, 29.78, 1.08],
        labels: ['Scrapers alta velocidad', 'Bots API', 'Crawlers lentos', 'Bots navegación repetitiva'],
        type: 'pie',
        marker: {colors: ['#ff6b6b', '#4ecdc4', '#1a535c', '#f9c80e']}
    }];
    Plotly.newPlot('botTypeChart', botTypeData, {title: 'Tipos de bots detectados'});

    // Country distribution chart
    var countryData = [{
        x: ['??', 'CL', 'AR', 'US', 'UY', 'BR'],
        y: [36000, 17000, 17000, 17000, 17000, 16000],
        type: 'bar',
        marker: {color: '#ff6b6b'}
    }];
    Plotly.newPlot('countryChart', countryData, {title: 'Tráfico por país'});

    // Bot country proportion chart
    var botCountryData = [{
        x: ['??', 'US', 'AR', 'UY', 'CL', 'BR'],
        y: [0.52, 0.13, 0.125, 0.123, 0.122, 0.12],
        type: 'bar',
        marker: {color: '#4ecdc4'}
    }];
    Plotly.newPlot('botCountryChart', botCountryData, {title: 'Proporción de tráfico automatizado por país'});

    // Gráfica de intervalos entre solicitudes
    var intervalData = [{
        x: [0, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000, 5500, 6000, 6500, 7000, 7500, 8000],
        y: [11, 14, 6, 3, 10, 8, 12, 9, 8, 5, 4, 3, 1, 0, 1, 0, 1],
        type: 'bar',
        marker: {color: '#ff6b6b'}
    }];

    var intervalLayout = {
        title: 'Distribución de desviación estándar de intervalos entre solicitudes por sesión',
        xaxis: {title: 'Desviación estándar (segundos)'},
        yaxis: {title: 'Frecuencia'},
        shapes: [{
            type: 'line',
            x0: 500,
            y0: 0,
            x1: 500,
            y1: 14,
            line: {
                color: 'red',
                width: 2,
                dash: 'dash'
            }
        }],
        annotations: [{
            x: 500,
            y: 14,
            xref: 'x',
            yref: 'y',
            text: 'Umbral de sospecha: 0.5 segundos',
            showarrow: true,
            arrowhead: 2,
            ax: 20,
            ay: -30,
            font: {color: 'red'}
        }]
    };

    Plotly.newPlot('intervalChart', intervalData, intervalLayout);

    // Bot distribution by country
    var botDistData = [{
        x: ['??', 'US', 'AR', 'UY', 'CL', 'BR'],
        y: [98, 20, 19, 20, 20, 20],
        name: 'Bots API',
        type: 'bar',
        marker: {color: '#4ecdc4'}
    }, {
        x: ['??', 'US', 'AR', 'UY', 'CL', 'BR'],
        y: [1, 80, 81, 80, 80, 80],
        name: 'Crawlers lentos',
        type: 'bar',
        marker: {color: '#a991d4'}
    }, {
        x: ['??', 'US', 'AR', 'UY', 'CL', 'BR'],
        y: [1, 0, 0, 0, 0, 0],
        name: 'Bots navegación',
        type: 'bar',
        marker: {color: '#555555'}
    }];

    var layout = {
        barmode: 'stack',
        title: 'Distribución de tipos de bot por país',
        xaxis: {title: 'País'},
        yaxis: {title: 'Porcentaje (%)'}
    };

    Plotly.newPlot('botDistributionByCountry', botDistData, layout);

    // Confusion matrix chart
    var confusionData = [{
        z: [[82267, 1406], [2437, 28298]],
        x: ['Normal', 'Bot'],
        y: ['Normal', 'Bot'],
        type: 'heatmap',
        colorscale: 'Blues',
        showscale: false,
        text: [[82267, 1406], [2437, 28298]],
        texttemplate: '%{text}',
        textfont: {color: 'white'}
    }];
    Plotly.newPlot('confusionMatrix', confusionData, {
        title: 'Matriz de Confusión',
        xaxis: {title: 'Predicción'},
        yaxis: {title: 'Valor Real'}
    });

    // Open default tab
    document.getElementById("defaultOpen").click();
});
    </script>
</body>
</html>
